---
title: "Guías de problemas"
toc: false
view: source
---

## Guía 1: Teorema de Bayes y modelo Beta-Binomial

Recomiendo hacer, además de estos, los ejercicios de los capítulos 1 a 3 del libro [Bayes Rules!](https://www.bayesrulesbook.com/).

1.  Supongamos que queremos averiguar cuál es la superficie de la Tierra cubierta por agua, $\theta$. Para eso, lanzamos al aire un globo terráqueo y al atraparlo, registramos si nuestro dedo índice de la mano derecha quedó marcando agua o tierra. De esta manera obtenemos una secuencia de muestras aleatorias de una variable $\text{Bernoulli}(\theta)$ independientes.

    a.  Con ese procedimiento se obtienen 4 "agua" (**A**) y 11 "tierra" (**T**). Usando un prior uniforme para $\theta$, obtener la distribución posterior para $\theta$.
    b.  Usando la distribución posterior calculada, obtener la distribución "posterior predictive" para las siguiente 5 muestras aleatorias
    c.  Usar la distribución "posterior predictive" para calcular la probabilidad de obtener 3 o más **A** en las siguiente 5 realizaciones.

2.  Siguiente el procedimiento del ejercicio anterior y partiendo de una distribución uniforme, graficar la distribución posterior luego de observar **A**. Luego, usando esa distribución posterior como prior, calcular y graficar la distribición posterior luego de observar **T**. Continuar este proceso para ver cómo se actualiza secuencialmente la distribución posterior cuando sucesivamente obtenemos (después de las dos primeras muestras aleatorias) **{A, A, A, T, A, T, A}**.

3.  Repetir el ejercicio 2 pero partir de un prior triangular, con máximo en $\theta = 0.5$. Para hacerlo, hacer una aproximación de grilla para calcular la posterior. Esto es:

    a.  Definir un vector de valores de $\theta$ en los cuales se quiere estimar la posterior.
    b.  Calcular el prior para cada valor $\theta$ en esa grilla.
    c.  Calcular la función de likelihood para valor del parámetro.
    d.  Calcular la posterior no normalizada multiplicando el prior por el likelihood.
    e.  Normalizar la posterior dividiendo por la suma de todos sus valores.

4.  Crear una función que genere $N$ datos del proceso aleatorio descripto en el ejercicio 1 tomando como parámetros $N$ y $\theta$. Crear otra función que calcule la distribución posterior partiendo de un prior uniforme, genere muestras de esta distribución y con esas muestras devuelva un intervalo de credibilidad del 50% $\theta$. Con esta función, estimar el número mínimo de muestras aleatorias que se necesitan para estimar $\theta$ con un intervalo de credibilidad de ancho menor a 0.1.

5.  Supongamos que estamos de espaldas a una mesa de pool separada en dos por una línea vertical. Juan y Alicia participan del siguiente juego. Tiran una pelota a la mesa que cae en un punto cualquiera, al azar. Si cae a la izquierda de la línea, Alicia gana 1 punto. Si cae a la derecha, Juan gana 1 punto. Gana el primero que llega a 6 puntos. Después de tirar 8 bolas, Alicia suma 5 puntos y Juan 3.

    a.  Calcular la distribución posterior para la probabilidad $\theta$ de que Juan gane el juego.
    b.  Tomar muestras de la posterior y con ellas obtener la esperanza de $\theta$. Comparar con el resultado visto en clase.
    c.  Simular este juego para obtener la probabilidad esperada de que gana Juan el juego, entendida como la cantidad de veces que gana Juan el juego condicional a que va perdiendo 5 a 3.

## Guía 2: Familias conjugadas

1.  Se observa la realización de $n$ variables aleatorias Poisson independientes de parámetro $\lambda$. Escribir y graficar la función de Likelihood $L(\lambda)$ para cada caso:

    a.  $(y_1,y_2,y_3) = (3, 7 ,19)$.
    b.  $(y_1,y_2,y_3,y_4) = (12, 12 ,12, 0)$.
    c.  $y_1 = 12$.
    d.  $(y_1,y_2,y_3,y_4,y_5) = (16, 10 ,17, 11, 11)$.

2.  Suponiendo un prior $\lambda \sim \text{Gamma}(24,2)$, especificar y graficar la distribución posterior para $\lambda$ correspondiente a cada escenario del ejercicio anterior.

3.  Repetir el ejercicio anterior suponiendo un prior $\lambda \sim \text{Gamma}(2,2)$

4.  Supongamos que uno tiene una variable aleatoria $Y$ que puede modelar con una distribución geométrica. Es decir que $P(Y=y \mid \theta) = \theta ~ (1-\theta)^{y-1}$ para $y \in \{1, 2, 3, ...\}$. Se utiliza un prior $Beta(a,b)$ para $\theta$.

    a.  ¿Qué situación se representa con una variable aleatoria geométrica?
    b.  Derivar la distribución posterior para $\theta$ suponiendo que se observó $Y=y$. Identificar la distribución encontrada y sus parámetros.
    c.  El modelo Beta es un prior conjugado de la Geométrica?

5.  Supongamos que $\lambda$ es el promedio del número total de goles por partido del mundial de fútbol femenino. En este ejercicio vamos a analizar $\lambda$ usando el modelo Gamma-Poisson donde $Y_i$ es el número de goles que se hicieron en un partido $i$ del Mundial. Es decir que $P(Y_i \mid \lambda) = \text{Pois}(\lambda)$. Como prior, tomar: $P(\lambda) = \text{Gamma}(1, 0.25)$.

    a.  Graficar el conocimiento previo sobre $\lambda$.
    b.  ¿Por qué el modelo Poisson es razonable para Y_i?
    c.  Escribir la distribución posterior para $\lambda$ suponiendo que en los primeros tres partidos se meten $(y_1,y_2,y_3) = (3, 7 ,4)$ goles.
    d. Ahora usando datos reales, graficar la evolución (partido a partido) del conocimiento sobre $\lambda$. Los datos se pueden obtener 

```{r eval=FALSE}
library(fivethirtyeight)
library(dplyr)

data("wwc_2019_matches")
d <- wwc_2019_matches %>% 
  mutate(total = score1 + score2) %>% 
  select(total)

```


