[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Estimación Bayesiana",
    "section": "",
    "text": "Materia electiva de la Licenciatura en Ciencia de Datos.\n\n\n\n\n\n\n  \n  \n    Docente:\nGuillermo Solovey, Instituto de Cálculo.\n    Clases:\nDesde el Lunes 20 de Marzo al Lunes 3 de Julio.\n    Lunes:\nde 10 a 12hs en el aula 1115 (cero+infinito).\n    Martes:\nde 10 a 12hs en el laboratorio 1109 (cero+infinito).\n    Correlativa:\nIntroducción a la Estadística y la Ciencia de Datos.\n  \n  \n  \n\n\n\n\n\n\n Instituto de Cálculo\n\n\n Facultad de Ciencias Exactas y Naturales, UBA"
  },
  {
    "objectID": "cronograma.html",
    "href": "cronograma.html",
    "title": "Cronograma",
    "section": "",
    "text": "Nota: Este cronograma es muy preliminar. Se va a actualizar en Marzo.\n\n\n\n\n\n\n\n\n\n  \n  \n    \n      semana\n      fecha\n      tema\n      lectura\n      slides\n      notas\n      tp\n    \n  \n  \n    1\n\nIntroducción a estadística bayesiana\nBayes Rules! c.1-2\n\n\n\n    1\n\nLabo 01\n\n\n\n\n    2\n\nEl modelo Beta-Binomial\nBayes Rules! c.3\n\n\n\n    2\n\nTP1: Regla de Bayes y ejercicios de simulación\n\n\n\n\n    3\n\nBalance y secuencialidad. Familias conjugadas. Gamma-Poisson, Normal-Normal\nBayes Rules! c.4-5\n\n\n\n    3\n\nTP2: Beta-Binomial\n\n\n\n\n    4\n\nSimulación de la Posterior\nBayes Rules! c.6-7\n\n\n\n    4\n\nTP4\n\n\n\n\n    5\n\nInferencia Posterior y Predicción\nBayes Rules! c.8\n\n\n\n    5\n\nTP4\n\n\n\n\n    6\n\n\n\n\n\n\n    6\n\n\n\n\n\n\n    7\n\nRegresión lineal simple. Regularización LASSO y RIDGE.\nBayes Rules! c. 9, 10\n\n\n\n    7\n\nTP5\n\n\n\n\n    8\n\nRegresión lineal. Variables Categóricas. Evaluación de la calidad del ajuste.\nBayes Rules! c. 11.\n\n\n\n    8\n\nTP6\n\n\n\n\n    9\n\nRegresión de Poisson y Binomial Negativa\nBayes Rules! c.12\n\n\n\n    9\n\nTP7\n\n\n\n\n    10\n\nRegresión logística. Naive Bayes\nBayes Rules! c.13\n\n\n\n    10\n\nTP8\n\n\n\n\n    11\n\n\n\n\n\n\n    11\n\n\n\n\n\n\n    12\n\nModelos jerárquicos sin predictores\nBayes Rules! c.15-16\n\n\n\n    12\n\nTP9\n\n\n\n\n    13\n\nModelos jerárquicos con predictores\nBayes Rules! c.17\n\n\n\n    13\n\nTP10\n\n\n\n\n    14\n\nModelos jerárquicos de presicción y clasificación (no-normales)\nBayes Rules! c.18\n\n\n\n    14\n\nTP11\n\n\n\n\n    15\n\n\n\n\n\n\n    15\n\n\n\n\n\n\n    16\n\nPresentación final\n\n\n\n\n    16\n\nPresentación final"
  },
  {
    "objectID": "index.html#course-materials",
    "href": "index.html#course-materials",
    "title": "Estimación Bayesiana",
    "section": "Course materials",
    "text": "Course materials\n\nBooks\nWe’ll be working through two textbooks throughout the semester:\n\nRichard McElreath, Statistical Rethinking: A Bayesian Course with Examples in R and Stan\n\n\n\n\nAlicia A. Johnson, Miles Q. Ott, and Mine Dogucu, Bayes Rules! An Introduction to Applied Bayesian Modeling\n\n\n\nBayes Rules! is available online for free. The book for Statistical Rethinking is not free ($70 on Amazon), but Richard McElreath has provided 20 video lectures with accompanying slides and homework assignments and answer keys.\nWe’ll read all of Bayes Rules!, all of Statistical Rethinking, watch all of McElreath’s Statistical Rethinking lectures, and complete a bunch of the assignments and homework questions from both books.\n\nDocente\n\nDocente: Dr. Guillermo Solovey\nOficina: 2605, Edificio Cero+Infinito, Exactas-UBA\n\n\n\nFechas\n\nInscripción: Primer cuatrimestre 2023. Inicio de clases: semana del 20 de Marzo.\nDictado: Primer cuatrimestre 2023. Inicio de clases: semana del 20 de Marzo.\nHorarios: 4 horas semanales en días y horario a definir.\n\n\n\nCorrelativas\n\nIntroducción a la Estadística y la Ciencia de Datos.\n\n\n\nCódigo de inscripción en el SIU\n\nGrado: a definir\nDoctorado: a definir\n\n\n\nBibliografía\n\nVamos a usar principalmente Bayes Rules! y Statistical Rethinking.\n\n\n\n Instituto de Cálculo\n\n\n Facultad de Ciencias Exactas y Naturales, UBA"
  },
  {
    "objectID": "programa.html",
    "href": "programa.html",
    "title": "Programa",
    "section": "",
    "text": "Distinguir entre el enfoque estadístico frecuentista y bayesiano.\nConstruir modelos bayesianos para situaciones simples.\nUsar fluidamente R y Stan para implementar modelos estadísticos bayesianos.\nHacer predicciones e interpretar los resultados de un modelo bayesiano."
  },
  {
    "objectID": "programa.html#bibliografía",
    "href": "programa.html#bibliografía",
    "title": "Programa",
    "section": "Bibliografía",
    "text": "Bibliografía\nprincipal:\n\nAlicia A. Johnson, Miles Q. Ott, and Mine Dogucu, Bayes Rules! An Introduction to Applied Bayesian Modeling\nRichard McElreath, Statistical Rethinking: A Bayesian Course with Examples in R and Stan, 2nd edition.\n\n\ncomplementaria:\n\nBen Lambert, A Student’s Guide to Bayesian Statistics.\nOsvaldo A. Martin, Ravin Kumar y Junpeng Lao, Bayesian Modeling and Computation in Python.\nPeter D. Hoff, A first course in Bayesian statistical methods.\nCameron Davidson-Pilon, Bayesian methods for hackers: probabilistic programming and Bayesian inference.\nDavid Robinson, Introduction to empirical bayes: examples from baseball statistics.\nAndrew Gelman, Jennifer Hill, and Aki Vehtari, Regression and other stories."
  },
  {
    "objectID": "programa.html#programa",
    "href": "programa.html#programa",
    "title": "Programa",
    "section": "Programa",
    "text": "Programa\n\nUnidad 1\nFundamentos bayesianos: Aprender cómo pensar bayesianamente y cómo crear modelos bayesianos básicos.\nIntroducción a la estadística bayesiana. Diferencias entre estadística bayesiana y frecuentista. Pensar bayesianamente. Modelo beta-binomial. Equilibrio entre el prior y los datos. Análisis bayesiano secuencial. Familias conjugadas.\n\n\nUnidad 2\nSimulación y análisis de la distribución posterior: Herramientas computacionales para simular la distribución posterior en modelos bayesianos complejos.\nAnalizar modelos simulados y exactos para hacer inferencia y sacar conclusiones. Aproximar la distribución posterior. Método de grilla, Metrópolis-Hastings y Markov Chain Monte Carlo (MCMC). Implementación y diagnóstico en R. Estimación de parámetros Testeo de hipótesis. Predicción.\n\n\nUnidad 3\nModelos bayesianos de regresión y clasificación: Extender los modelos bayesianos a casos en los que la variable respuesta es contínua (regresión) y categórica (clasificación).\nRegresión Normal. Regresión múltiple. Variables de control y confusoras. Evaluación, diagnóstico y comparación de modelos de regresión. Regresión de Poisson. Naive-Bayes. Regresión logística.\n\n\nUnidad 4\nModelos bayesianos jerárquicos: Modelos bayesianos para datos multi-nivel, como datos longitudinales y de medidas repetidas.\nModelo complete-pool y no-pool. Modelos de pooling parcial. Modelo jerárquico normal sin predictores. Modelos de regresión y clasificación jerárquicos."
  },
  {
    "objectID": "index.html#docente",
    "href": "index.html#docente",
    "title": "Estimación Bayesiana",
    "section": "Docente",
    "text": "Docente\n\nDocente: Dr. Guillermo Solovey\nOficina: 2605, Edificio Cero+Infinito, Exactas-UBA"
  },
  {
    "objectID": "index.html#fechas",
    "href": "index.html#fechas",
    "title": "Estimación Bayesiana",
    "section": "Fechas",
    "text": "Fechas\n\nInscripción: desde el 22 de Febrero al 5 de Marzo de 2023.\nDictado: Primer cuatrimestre 2023. Inicio de clases: semana del 20 de Marzo.\nHorarios: 4 horas semanales en días y horario a definir."
  },
  {
    "objectID": "index.html#correlativas",
    "href": "index.html#correlativas",
    "title": "Estimación Bayesiana",
    "section": "Correlativas",
    "text": "Correlativas\n\nIntroducción a la Estadística y la Ciencia de Datos.\n\n\n\n Instituto de Cálculo\n\n\n Facultad de Ciencias Exactas y Naturales, UBA"
  },
  {
    "objectID": "index.html#código-de-inscripción-en-el-siu",
    "href": "index.html#código-de-inscripción-en-el-siu",
    "title": "Estimación Bayesiana",
    "section": "Código de inscripción en el SIU",
    "text": "Código de inscripción en el SIU\n\nGrado: a definir\nDoctorado: a definir"
  },
  {
    "objectID": "index.html#bibliografía",
    "href": "index.html#bibliografía",
    "title": "Estimación Bayesiana",
    "section": "Bibliografía",
    "text": "Bibliografía\n\n?var:course.text\n\n\n\n Instituto de Cálculo\n\n\n Facultad de Ciencias Exactas y Naturales, UBA"
  },
  {
    "objectID": "eb2023.html",
    "href": "eb2023.html",
    "title": "Estimación bayesiana",
    "section": "",
    "text": "Una máquina funciona perfectamente mientras tiene una sustancia que la protege. Sin embargo, esta sustancia se va consumiendo y cuando se agota, después de un tiempo \\(\\theta\\), puede fallar en algún momento aleatorio que sigue una distribución exponencial. El tiempo que pasa hasta que produce la falla,\\(x\\), sigue una distribución exponencial truncada dada por:\n\\[\nf(x|\\theta) = \\left\\{\n\\begin{array}{ll}\n      0 & x < \\theta \\\\\n      e^{-(x-\\theta)} & x > \\theta \\\\\n\\end{array}\n\\right.\n\\]\nSe mide el tiempo de falla de tres máquinas obteniendo: \\(\\text{datos} = \\{10,12,15\\}\\). El objetivo es, a partir de estos datos, inferir \\(\\theta\\). En particular, queremos un intervalo de confianza frecuentista y un intervalo de credibilidad bayesiano para \\(\\theta\\)."
  },
  {
    "objectID": "eb2023.html#intervalo-frecuentista",
    "href": "eb2023.html#intervalo-frecuentista",
    "title": "Estimación bayesiana",
    "section": "Intervalo frecuentista",
    "text": "Intervalo frecuentista\nEl intervalo de confianza asintótico para un estimador \\(\\theta\\) es \\(\\text{CI}_{95} \\approx \\hat{\\theta} \\pm 2~\\sqrt{\\mathbb{V}(\\hat{\\theta})}\\). Observando que \\(y = x - \\theta\\) es exponencial con parámetro 1, la esperanza de \\(y\\) es \\(E(y)=1\\) y la varianza \\(\\mathbb{V}(y)=1\\), para \\(x\\) tenemos:\n\\[\n\\begin{array}{l}\nE(x) = \\theta + 1 \\\\\n\\mathbb{V}(x) = \\mathbb{V}(y+\\theta) = 1\n\\end{array}\n\\]\nPor lo tanto, un estimador de \\(\\theta\\) es:\n\\[\n\\hat{\\theta} = \\frac{1}{N} \\sum_{i=1}^N x_i - 1 \\\\\n\\] que tiene una varianza \\(\\mathbb{V}(\\hat{\\theta}) = \\frac{1}{N^2} \\sum \\mathbb{V}(x_i) = \\frac{1}{N}\\). Por lo tanto, el intervalo de confianza del 95% asintótico es:\n\\[\n\\text{CI}_{95} \\approx (\\hat{\\theta} - 2 / \\sqrt{N}, \\hat{\\theta} + 2 / \\sqrt{N}) \\\\\n\\]\nUsando los \\(\\text{datos} = \\{10,12,15\\}\\), obtenemos que:\n\\[\n\\begin{array}{ll}\n\\color{blue}{ \\hat{\\theta}   } & \\color{blue}{ \\approx 11.3 } \\\\\n\\color{blue}{ \\text{CI}_{95} } & \\color{blue}{ \\approx (10.2, 12.5) }\n\\end{array}\n\\]\nEste intervalo de confianza llama la atención porque claramente \\(\\theta\\), el tiempo a partir del cual la máquina comienza a fallar no puede ser mayor que el mínimo entre todos los tiempos de falla que se midieron. O sea: \\(\\theta <10\\)!!"
  },
  {
    "objectID": "eb2023.html#intervalo-bayesiano",
    "href": "eb2023.html#intervalo-bayesiano",
    "title": "Estimación bayesiana",
    "section": "Intervalo bayesiano",
    "text": "Intervalo bayesiano\nTenemos que encontrar la distribución de probabilidad posterior \\(P(\\theta|\\text{datos})\\):\n\\[\n\\require{mathtools}\n\\definecolor{bayesred}{RGB}{147, 30, 24}\n\\definecolor{bayesblue}{RGB}{32, 35, 91}\n\\definecolor{bayesorange}{RGB}{218, 120, 1}\n\\definecolor{grey}{RGB}{128, 128, 128}\n\\color{bayesorange} \\overbracket[0.25pt]{P(\\theta \\mid \\text{datos})}^{\\text{Posterior}} \\sim\n\\color{bayesred}    \\overbracket[0.25pt]{P(\\theta)}^{\\text{Prior}} \\times\n\\color{bayesblue}   \\overbracket[0.25pt]{P(\\text{datos} \\mid \\theta)}^{\\text{Likelihood}}\n\\] Como prior vamos a usar una distribución uniforme entre 0 y algún número elevado \\(\\theta_{max}\\) que sea superior a cualquier tiempo de falla razonable (por ejemplo \\(\\theta_{max}=10^{10}\\)). El likelihood es:\n\\[\n\\begin{array}{ll}\nL(\\theta) & = P(\\text{datos} \\mid \\theta) = \\prod_{i=1}^{N} f(x_i \\mid \\theta) \\\\\n& \\sim \\left\\{ \\begin{array}{ll}\n      \\exp(N\\theta) & \\theta < \\text{min}(x_i) \\\\\n      0             & \\theta > \\text{min}(x_i)\n\\end{array}\n\\right.\n\\end{array}\n\\]\nPor lo tanto, la distribución posterior es:\n\\[\n\\definecolor{bayesorange}{RGB}{218, 120, 1}\n\\color{bayesorange}{P(\\theta \\mid \\text{datos})}\n\\sim \\left\\{ \\begin{array}{ll}\n      e^{3\\theta} & 0 < \\theta < 10 \\\\\n      0             & \\theta > 10\n\\end{array}\n\\right.\n\\] Ahora, un intervalo del 95% de credibilidad para \\(\\theta\\) es un intervalo \\((a,10)\\) tal que\n\\[\n\\frac{\\int_a^{10} e^{3\\theta} ~  d\\theta }{\\int_0^{10} e^{3\\theta} ~  d\\theta } = 0.95\n\\]\nHaciendo la cuenta se obtiene que \\(a=9\\) y por lo tanto, condicional al modelo y a los datos, podemos afirmar que existe una probabilidad del 95% de que el tiempo en el cual se agota el líquido necesario para que funcione la máquina, \\(\\theta\\), esté entre 9 y 10.\n\n\n\n\n\n\n\n\n\n\n\nRecordar\n\n\n\nUn intervalo de confianza no es una afirmación probabilística sobre \\(\\theta\\)."
  },
  {
    "objectID": "eb2023.html#funciona-mal-el-intervalo-frecuentista",
    "href": "eb2023.html#funciona-mal-el-intervalo-frecuentista",
    "title": "Estimación bayesiana",
    "section": "¿Funciona mal el intervalo frecuentista?",
    "text": "¿Funciona mal el intervalo frecuentista?\n¿Por qué el intervalo frecuentista queda enteramente por afuera de la región aceptable para el parámetro \\(\\theta\\)? El intervalo de confianza frecuentista, por definición, contiene al parámetro verdadero con una probabilidad del 95%. Esto quiere decir que si tomamos muchas muestras de tamaño 3 (como en este problema) y para cada muestra aleatoria calculamos el intervalo de confianza, el 95% van a incluir al verdadero. Lo que ocurre con estos datos es que por mala suerte nos tocó uno de los intervalos de ese 5% que no contiene al verdadero.\nVerifiquemos que el intervalo de confianza asintótico funciona bien. Al ser asintótico, debería ser correcto para un tamaño de muestra grande, pero en este caso \\(n=3\\) y podría no ser válido como intervalo de confianza. Para ver si es el caso, vamos a simular muchas muestras aleatorias de \\(n=3\\) para un parámetro \\(\\theta=10\\) fijo y para cada una vamos a verificar si el intervalo de confianza contiene al valor verdadero.\n\nn     = 3\ntheta = 10\n\nNit = 10000\nok  = 0\nfor (i in 1:Nit){\n\n  x     = rexp(n, 1) + theta\n  theta.e = mean(x) - 1\n  ci      = c(theta.e - 2/sqrt(n), theta.e + 2/sqrt(n))\n  \n  if (theta > ci[1] & theta < ci[2]){\n    ok = ok + 1\n  }\n}\n\n# cobertura del intervalo de confianza\nprint(ok/Nit)\n\n[1] 0.954\n\n\nDe las 10.000 muestras aleatorias con \\(N=3\\) simuladas alrededor del 95% contiene al parámetro \\(\\theta=10\\)."
  },
  {
    "objectID": "eb2023.html#problema",
    "href": "eb2023.html#problema",
    "title": "Estimación bayesiana",
    "section": "Problema",
    "text": "Problema\nOriginalmente planteado por Berger y Wolpert (1984), yo lo tomé del libro de Wasserman “All of Statistics” (¡excelente!).\nSupongamos que hay dos variables aleatorias \\(X_1\\) y \\(X_2\\) independientes que pueden tomar el valor 1 o -1 con igual probabilidad (¡dos monedas!). Definimos otras dos variables así:\n\\[\n\\begin{array}{ll}\nY_1 &= \\theta + X_1 \\\\\nY_2 &= \\theta + X_2\n\\end{array}\n\\] Supongamos que sólo se miden \\(Y_1\\) e \\(Y_2\\) y se quiere estimar \\(\\theta\\) que está fijo.\n1- Verificar que \\(C\\), definido a continuación, es un intervalo de confianza del 75% para \\(\\theta\\):\n\\[\nC = \\left\\{\n\\begin{array}{ll}\n      Y_1 - 1        & \\text{si } Y_1 = Y_2 \\\\\n      (Y_1 + Y_2)/2  & \\text{si } Y_1 \\ne Y_2\n\\end{array}\n\\right.\n\\]\n2- Supongan ahora que se mide en un experimento \\(y_1 = 15\\) y \\(y_2=17\\), ¿cuál es el intervalo de confianza del 75% para \\(\\theta\\)? ¿cuánto vale \\(\\theta\\)?"
  },
  {
    "objectID": "intervalos.html",
    "href": "intervalos.html",
    "title": "Estimación bayesiana",
    "section": "",
    "text": "Una máquina funciona perfectamente mientras tiene una sustancia que la protege. Sin embargo, esta sustancia se va consumiendo y cuando se agota, después de un tiempo \\(\\theta\\), puede fallar en algún momento aleatorio que sigue una distribución exponencial. El tiempo que pasa hasta que produce la falla,\\(x\\), sigue una distribución exponencial truncada dada por:\n\\[\nf(x|\\theta) = \\left\\{\n\\begin{array}{ll}\n      0 & x < \\theta \\\\\n      e^{-(x-\\theta)} & x > \\theta \\\\\n\\end{array}\n\\right.\n\\]\nSe mide el tiempo de falla de tres máquinas obteniendo: \\(\\text{datos} = \\{10,12,15\\}\\). El objetivo es, a partir de estos datos, inferir \\(\\theta\\). En particular, queremos un intervalo de confianza frecuentista y un intervalo de credibilidad bayesiano para \\(\\theta\\)."
  },
  {
    "objectID": "intervalos.html#intervalo-frecuentista",
    "href": "intervalos.html#intervalo-frecuentista",
    "title": "Estimación bayesiana",
    "section": "Intervalo frecuentista",
    "text": "Intervalo frecuentista\nEl intervalo de confianza asintótico para un estimador \\(\\theta\\) es \\(\\text{CI}_{95} \\approx \\hat{\\theta} \\pm 2~\\sqrt{\\mathbb{V}(\\hat{\\theta})}\\). Observando que \\(y = x - \\theta\\) es exponencial con parámetro 1, la esperanza de \\(y\\) es \\(E(y)=1\\) y la varianza \\(\\mathbb{V}(y)=1\\), para \\(x\\) tenemos:\n\\[\n\\begin{array}{l}\nE(x) = \\theta + 1 \\\\\n\\mathbb{V}(x) = \\mathbb{V}(y+\\theta) = 1\n\\end{array}\n\\]\nPor lo tanto, un estimador de \\(\\theta\\) es:\n\\[\n\\hat{\\theta} = \\frac{1}{N} \\sum_{i=1}^N x_i - 1 \\\\\n\\] que tiene una varianza \\(\\mathbb{V}(\\hat{\\theta}) = \\frac{1}{N^2} \\sum \\mathbb{V}(x_i) = \\frac{1}{N}\\). Por lo tanto, el intervalo de confianza del 95% asintótico es:\n\\[\n\\text{CI}_{95} \\approx (\\hat{\\theta} - 2 / \\sqrt{N}, \\hat{\\theta} + 2 / \\sqrt{N}) \\\\\n\\]\nUsando los \\(\\text{datos} = \\{10,12,15\\}\\), obtenemos que:\n\\[\n\\begin{array}{ll}\n\\color{blue}{ \\hat{\\theta}   } & \\color{blue}{ \\approx 11.3 } \\\\\n\\color{blue}{ \\text{CI}_{95} } & \\color{blue}{ \\approx (10.2, 12.5) }\n\\end{array}\n\\]\nEste intervalo de confianza llama la atención porque claramente \\(\\theta\\), el tiempo a partir del cual la máquina comienza a fallar no puede ser mayor que el mínimo entre todos los tiempos de falla que se midieron. O sea: \\(\\theta <10\\)!!"
  },
  {
    "objectID": "intervalos.html#intervalo-bayesiano",
    "href": "intervalos.html#intervalo-bayesiano",
    "title": "Estimación bayesiana",
    "section": "Intervalo bayesiano",
    "text": "Intervalo bayesiano\nTenemos que encontrar la distribución de probabilidad posterior \\(P(\\theta|\\text{datos})\\):\n\\[\n\\require{mathtools}\n\\definecolor{bayesred}{RGB}{147, 30, 24}\n\\definecolor{bayesblue}{RGB}{32, 35, 91}\n\\definecolor{bayesorange}{RGB}{218, 120, 1}\n\\definecolor{grey}{RGB}{128, 128, 128}\n\\color{bayesorange} \\overbracket[0.25pt]{P(\\theta \\mid \\text{datos})}^{\\text{Posterior}} \\sim\n\\color{bayesred}    \\overbracket[0.25pt]{P(\\theta)}^{\\text{Prior}} \\times\n\\color{bayesblue}   \\overbracket[0.25pt]{P(\\text{datos} \\mid \\theta)}^{\\text{Likelihood}}\n\\] Como prior vamos a usar una distribución uniforme entre 0 y algún número elevado \\(\\theta_{max}\\) que sea superior a cualquier tiempo de falla razonable (por ejemplo \\(\\theta_{max}=10^{10}\\)). El likelihood es:\n\\[\n\\begin{array}{ll}\nL(\\theta) & = P(\\text{datos} \\mid \\theta) = \\prod_{i=1}^{N} f(x_i \\mid \\theta) \\\\\n& \\sim \\left\\{ \\begin{array}{ll}\n      \\exp(N\\theta) & \\theta < \\text{min}(x_i) \\\\\n      0             & \\theta > \\text{min}(x_i)\n\\end{array}\n\\right.\n\\end{array}\n\\]\nPor lo tanto, la distribución posterior es:\n\\[\n\\definecolor{bayesorange}{RGB}{218, 120, 1}\n\\color{bayesorange}{P(\\theta \\mid \\text{datos})}\n\\sim \\left\\{ \\begin{array}{ll}\n      e^{3\\theta} & 0 < \\theta < 10 \\\\\n      0             & \\theta > 10\n\\end{array}\n\\right.\n\\] Ahora, un intervalo del 95% de credibilidad para \\(\\theta\\) es un intervalo \\((a,10)\\) tal que\n\\[\n\\frac{\\int_a^{10} e^{3\\theta} ~  d\\theta }{\\int_0^{10} e^{3\\theta} ~  d\\theta } = 0.95\n\\]\nHaciendo la cuenta se obtiene que \\(a=9\\) y por lo tanto, condicional al modelo y a los datos, podemos afirmar que existe una probabilidad del 95% de que el tiempo en el cual se agota el líquido necesario para que funcione la máquina, \\(\\theta\\), esté entre 9 y 10.\n\n\n\n\n\n\n\n\n\n\n\nRecordar\n\n\n\nUn intervalo de confianza no es una afirmación probabilística sobre \\(\\theta\\)."
  },
  {
    "objectID": "intervalos.html#funciona-mal-el-intervalo-frecuentista",
    "href": "intervalos.html#funciona-mal-el-intervalo-frecuentista",
    "title": "Estimación bayesiana",
    "section": "¿Funciona mal el intervalo frecuentista?",
    "text": "¿Funciona mal el intervalo frecuentista?\n¿Por qué el intervalo frecuentista queda enteramente por afuera de la región aceptable para el parámetro \\(\\theta\\)? El intervalo de confianza frecuentista, por definición, contiene al parámetro verdadero con una probabilidad del 95%. Esto quiere decir que si tomamos muchas muestras de tamaño 3 (como en este problema) y para cada muestra aleatoria calculamos el intervalo de confianza, el 95% van a incluir al verdadero. Lo que ocurre con estos datos es que por mala suerte nos tocó uno de los intervalos de ese 5% que no contiene al verdadero.\nVerifiquemos que el intervalo de confianza asintótico funciona bien. Al ser asintótico, debería ser correcto para un tamaño de muestra grande, pero en este caso \\(n=3\\) y podría no ser válido como intervalo de confianza. Para ver si es el caso, vamos a simular muchas muestras aleatorias de \\(n=3\\) para un parámetro \\(\\theta=10\\) fijo y para cada una vamos a verificar si el intervalo de confianza contiene al valor verdadero.\n\nn     = 3\ntheta = 10\n\nNit = 10000\nok  = 0\nfor (i in 1:Nit){\n\n  x     = rexp(n, 1) + theta\n  theta.e = mean(x) - 1\n  ci      = c(theta.e - 2/sqrt(n), theta.e + 2/sqrt(n))\n  \n  if (theta > ci[1] & theta < ci[2]){\n    ok = ok + 1\n  }\n}\n\n# cobertura del intervalo de confianza\nprint(ok/Nit)\n\n[1] 0.9574\n\n\nDe las 10.000 muestras aleatorias con \\(N=3\\) simuladas alrededor del 95% contiene al parámetro \\(\\theta=10\\)."
  },
  {
    "objectID": "intervalos.html#problema",
    "href": "intervalos.html#problema",
    "title": "Estimación bayesiana",
    "section": "Problema",
    "text": "Problema\nOriginalmente planteado por Berger y Wolpert (1984), yo lo tomé del libro de Wasserman “All of Statistics” (¡excelente!).\nSupongamos que hay dos variables aleatorias \\(X_1\\) y \\(X_2\\) independientes que pueden tomar el valor 1 o -1 con igual probabilidad (¡dos monedas!). Definimos otras dos variables así:\n\\[\n\\begin{array}{ll}\nY_1 &= \\theta + X_1 \\\\\nY_2 &= \\theta + X_2\n\\end{array}\n\\] Supongamos que sólo se miden \\(Y_1\\) e \\(Y_2\\) y se quiere estimar \\(\\theta\\) que está fijo.\n1- Verificar que \\(C\\), definido a continuación, es un intervalo de confianza del 75% para \\(\\theta\\):\n\\[\nC = \\left\\{\n\\begin{array}{ll}\n      Y_1 - 1        & \\text{si } Y_1 = Y_2 \\\\\n      (Y_1 + Y_2)/2  & \\text{si } Y_1 \\ne Y_2\n\\end{array}\n\\right.\n\\]\n2- Supongan ahora que se mide en un experimento \\(y_1 = 15\\) y \\(y_2=17\\), ¿cuál es el intervalo de confianza del 75% para \\(\\theta\\)? ¿cuánto vale \\(\\theta\\)?"
  },
  {
    "objectID": "ejercicios.html",
    "href": "ejercicios.html",
    "title": "Guías de problemas",
    "section": "",
    "text": "Recomiendo hacer, además de estos, los ejercicios de los capítulos 1 a 3 del libro Bayes Rules!.\n\nSupongamos que queremos averiguar cuál es la superficie de la Tierra cubierta por agua, \\(\\theta\\). Para eso, lanzamos al aire un globo terráqueo y al atraparlo, registramos si nuestro dedo índice de la mano derecha quedó marcando agua o tierra. De esta manera obtenemos una secuencia de muestras aleatorias de una variable \\(\\text{Bernoulli}(\\theta)\\) independientes.\n\nCon ese procedimiento se obtienen 4 “agua” (A) y 11 “tierra” (T). Usando un prior uniforme para \\(\\theta\\), obtener la distribución posterior para \\(\\theta\\).\nUsando la distribución posterior calculada, obtener la distribución “posterior predictive” para las siguiente 5 muestras aleatorias\nUsar la distribución “posterior predictive” para calcular la probabilidad de obtener 3 o más A en las siguiente 5 realizaciones.\n\nSiguiente el procedimiento del ejercicio anterior y partiendo de una distribución uniforme, graficar la distribución posterior luego de observar A. Luego, usando esa distribución posterior como prior, calcular y graficar la distribición posterior luego de observar T. Continuar este proceso para ver cómo se actualiza secuencialmente la distribución posterior cuando sucesivamente obtenemos (después de las dos primeras muestras aleatorias) {A, A, A, T, A, T, A}.\nRepetir el ejercicio 2 pero partir de un prior triangular, con máximo en \\(\\theta = 0.5\\). Para hacerlo, hacer una aproximación de grilla para calcular la posterior. Esto es:\n\nDefinir un vector de valores de \\(\\theta\\) en los cuales se quiere estimar la posterior.\nCalcular el prior para cada valor \\(\\theta\\) en esa grilla.\nCalcular la función de likelihood para valor del parámetro.\nCalcular la posterior no normalizada multiplicando el prior por el likelihood.\nNormalizar la posterior dividiendo por la suma de todos sus valores.\n\nCrear una función que genere \\(N\\) datos del proceso aleatorio descripto en el ejercicio 1 tomando como parámetros \\(N\\) y \\(\\theta\\). Crear otra función que calcule la distribución posterior partiendo de un prior uniforme, genere muestras de esta distribución y con esas muestras devuelva un intervalo de credibilidad del 50% \\(\\theta\\). Con esta función, estimar el número mínimo de muestras aleatorias que se necesitan para estimar \\(\\theta\\) con un intervalo de credibilidad de ancho menor a 0.1.\nSupongamos que estamos de espaldas a una mesa de pool separada en dos por una línea vertical. Juan y Alicia participan del siguiente juego. Tiran una pelota a la mesa que cae en un punto cualquiera, al azar. Si cae a la izquierda de la línea, Alicia gana 1 punto. Si cae a la derecha, Juan gana 1 punto. Gana el primero que llega a 6 puntos. Después de tirar 8 bolas, Alicia suma 5 puntos y Juan 3.\n\nCalcular la distribución posterior para la probabilidad \\(\\theta\\) de que Juan gane el juego.\nTomar muestras de la posterior y con ellas obtener la esperanza de \\(\\theta\\). Comparar con el resultado visto en clase.\nSimular este juego para obtener la probabilidad esperada de que gana Juan el juego, entendida como la cantidad de veces que gana Juan el juego condicional a que va perdiendo 5 a 3."
  },
  {
    "objectID": "ejercicios.html#guía-2-familias-conjugadas",
    "href": "ejercicios.html#guía-2-familias-conjugadas",
    "title": "Guías de problemas",
    "section": "Guía 2: Familias conjugadas",
    "text": "Guía 2: Familias conjugadas\n\nSe observa la realización de \\(n\\) variables aleatorias Poisson independientes de parámetro \\(\\lambda\\). Escribir y graficar la función de Likelihood \\(L(\\lambda)\\) para cada caso:\n\n\\((y_1,y_2,y_3) = (3, 7 ,19)\\).\n\\((y_1,y_2,y_3,y_4) = (12, 12 ,12, 0)\\).\n\\(y_1 = 12\\).\n\\((y_1,y_2,y_3,y_4,y_5) = (16, 10 ,17, 11, 11)\\).\n\nSuponiendo un prior \\(\\lambda \\sim \\text{Gamma}(24,2)\\), especificar y graficar la distribución posterior para \\(\\lambda\\) correspondiente a cada escenario del ejercicio anterior.\nRepetir el ejercicio anterior suponiendo un prior \\(\\lambda \\sim \\text{Gamma}(2,2)\\)\nSupongamos que uno tiene una variable aleatoria \\(Y\\) que puede modelar con una distribución geométrica. Es decir que \\(P(Y=y \\mid \\theta) = \\theta ~ (1-\\theta)^{y-1}\\) para \\(y \\in \\{1, 2, 3, ...\\}\\). Se utiliza un prior \\(Beta(a,b)\\) para \\(\\theta\\).\n\n¿Qué situación se representa con una variable aleatoria geométrica?\nDerivar la distribución posterior para \\(\\theta\\) suponiendo que se observó \\(Y=y\\). Identificar la distribución encontrada y sus parámetros.\nEl modelo Beta es un prior conjugado de la Geométrica?\n\nSupongamos que \\(\\lambda\\) es el promedio del número total de goles por partido del mundial de fútbol femenino. En este ejercicio vamos a analizar \\(\\lambda\\) usando el modelo Gamma-Poisson donde \\(Y_i\\) es el número de goles que se hicieron en un partido \\(i\\) del Mundial. Es decir que \\(P(Y_i \\mid \\lambda) = \\text{Pois}(\\lambda)\\). Como prior, tomar: \\(P(\\lambda) = \\text{Gamma}(1, 0.25)\\).\n\nGraficar el conocimiento previo sobre \\(\\lambda\\).\n¿Por qué el modelo Poisson es razonable para Y_i?\nEscribir la distribución posterior para \\(\\lambda\\) suponiendo que en los primeros tres partidos se meten \\((y_1,y_2,y_3) = (3, 7 ,4)\\) goles.\nAhora usando datos reales, graficar la evolución (partido a partido) del conocimiento sobre \\(\\lambda\\). Los datos se pueden obtener\n\n\n\nlibrary(fivethirtyeight)\nlibrary(dplyr)\n\ndata(\"wwc_2019_matches\")\nd <- wwc_2019_matches %>% \n  mutate(total = score1 + score2) %>% \n  select(total)"
  },
  {
    "objectID": "ejercicios.html#guía-3-familias-conjugadas",
    "href": "ejercicios.html#guía-3-familias-conjugadas",
    "title": "Guías de problemas",
    "section": "Guía 3: Familias conjugadas",
    "text": "Guía 3: Familias conjugadas\n\nSimular 10000 datos de una distribución Beta(3,7). Graficar un histograma de los datos y la distribución teórica superpuesta. Dar tres medidas de resumen de la distribución usando los datos simulados.\nRepetir el ejercicio 1 para la distribución Gamma(4,2) y para la Normal(4,1).\nSupongamos que tomaron datos \\(y\\) y con un modelo bayesiano llegaron a que la distribución posterior para la probabilidad de que respondan un mail dentro de las 24 horas es Beta(2,5). Les llega un nuevo mail. ¿Cuál es la probabilidad de que lo respondan en menos de 24 horas? Es decir, se pide \\(P(\\tilde y = 1 \\mid y)\\), la posterior predictive. Resolverlo de dos formas:\n\nCalculando analíticamente \\(P(\\tilde y = 1 \\mid y)\\).\nSimulando datos. Para esto:\n\ndfdsf\nsdfd"
  },
  {
    "objectID": "ejercicios.html#guía-3-simulaciones-y-muestreo-de-la-posterior",
    "href": "ejercicios.html#guía-3-simulaciones-y-muestreo-de-la-posterior",
    "title": "Guías de problemas",
    "section": "Guía 3: Simulaciones y muestreo de la posterior",
    "text": "Guía 3: Simulaciones y muestreo de la posterior\n\nSimular 10000 datos de una distribución Beta(3,7). Graficar un histograma de los datos y la distribución teórica superpuesta. Dar tres medidas de resumen de la distribución usando los datos simulados.\nRepetir el ejercicio 1 para la distribución Gamma(4,2) y para la Normal(4,1).\nSupongamos que tomaron datos \\(y\\) y con un modelo bayesiano llegaron a que la distribución posterior para la probabilidad de que respondan un mail dentro de las 24 horas, \\(\\theta\\), es Beta(2,5). Les llega un nuevo mail. ¿Cuál es la probabilidad de que lo respondan en menos de 24 horas? Es decir, se pide \\(P(\\tilde y = 1 \\mid y)\\), la posterior predictive. Resolverlo de dos formas:\n\nCalculando analíticamente \\(P(\\tilde y = 1 \\mid y)\\).\nSimulando datos. Para esto:\n\nGenerar 10000 valores simulados del parámetro \\(\\theta\\) usando la distribución posterior.\nPara cada valor del parámetro \\(\\theta_i\\), simular un \\(y_i\\) predicho.\n¿Cuál es la frecuencia de \\(y=1\\) entre los predichos? ¿Coincide con lo calculado en a?.\n\n\nSupongamos que quieren saber si los mails que reciben los lunes los responden más rápido que los que reciben los sábados. Con datos que recolectan de su propia experiencia llegan a que la distribución posterior para \\(\\theta_L\\) es Beta(3,7) (correspondiente a mails que llegan los lunes) y \\(\\theta_S\\) es Beta(4,8) para los que llegan los sábados. Para responder la pregunta simulando, sigan estos pasos:\n\nSimular 10000 valores de \\(\\theta_L\\) y \\(\\theta_S\\).\nCalcular, para cada para de valores \\(\\theta_L(i)\\) y \\(\\theta_S(i)\\), la diferencia \\(\\delta_i = \\theta_L(i) - \\theta_S(i)\\).\nUsar las muestras aleatorias \\(\\delta_i\\) para responder la pregunta. Por ejemplo, preguntarse por la probabilidad de que esa diferencia sea positiva.\n\nUn jardín botánico tiene tres especies de árboles, A, B y C. El 18% del total de los árboles está infectado con un plaga. Entre los infectados, 15% son A, 80% son B y 5% son C. Entre los no infectados 20% son A, 10% son B y 70% son C. Para monitorear el avance de la plaga, un empleado se acerca a un árbol cualquiera para examinarlo. Para resolver este ejercicio, simular datos de 10000 árboles.\n\nCuál es la probabilidad de que el árbol esté infectado (prior)?\nSi resulta que el árbol seleccionado es de la especie B. ¿Qué probabilidad tenía de haber seleccionado uno de esa especie?\nCuál es la probabilidad posterior de que el árbol seleccionado, de la especie B, esté infectado?\nComparar la probabilidad a priori de que el árbol esté infectado con la probabilidad posterior (luego de saber que el árbol seleccionado es de la especie B)?\nComparar los resultados de las simulaciones con el resultado exacto usando la regla de Bayes.\n\nImplementar el algoritmo de Metropolis-Hastings para conseguir muestras de una distribución \\(\\text{Normal}(\\mu=0.4, \\sigma=0.6)\\). Construir una función que tome como argumento el largo de la cadena (número de muestras), el valor inicial y algún parámetro necesario de la función de propuesta.\n(BayesRules 7.15) Identificar una pregunta que se pueda responder con un modelo Beta-Binomial para la probabilidad \\(\\theta\\) de que ocurra algo. Por ejemplo: proporción de colectivos que vienen llenos cuando vienen a Exactas, etc.\n\nProponer un prior para \\(\\theta\\).\nJuntar datos (de verdad o inventados).\nSimular 2000 valores de \\(\\theta\\) obtenidos con el algoritmo de Metropolis-Hastings.\nGraficar la cadena resultante (secuencia de muestras). ¿Están satisfechos con el resultado? ¿A qué hay que estar atentos para aceptar las muestras?\n\n(BayesRules 7.16) Identificar una pregunta que se pueda responder con un modelo Normal para \\(\\mu\\), un valor medio de interés. Por ejemplo: la temperatura máxima promedio en Otoño en Buenos Aires, el tiempo medio de uso de celular diario, etc.\n\nProponer un prior para \\(\\mu\\).\nJuntar datos (de verdad o inventados).\nSimular 2000 valores de \\(\\mu\\) obtenidos con el algoritmo de Metropolis-Hastings. Usar \\(\\sigma\\) fijo.\nGraficar la cadena resultante (secuencia de muestras). ¿Están satisfechos con el resultado? ¿A qué hay que estar atentos para aceptar las muestras?"
  },
  {
    "objectID": "parcial.html",
    "href": "parcial.html",
    "title": "Parcial",
    "section": "",
    "text": "Va a jugar la selección Sub-20 de fútbol en Argentina después de la Chiqui tapia masterclass. Históricamente la selección marcó un promedio de dos goles por partido con una varianza de 0.5. En las primeras dos fechas los resultados fueron 1-0 y 0-0 a favor de Argentina.\n\nEscribir el prior y justificar la elección. prior de qué variable?.\nDeducir cuál sería la posterior. de qué variable.\nPara clasificar a la siguiente ronda la selección necesita al menos 3 goles en la próxima fecha. Calcular la probabilidad de clasificar, para eso generar 10000 datos del número predicho de goles a partir de 10000 muestras de la posterior y estimar la probabilidad de que Argentina haga 3 o más goles en la siguiente fecha.\nPara el Sub-20 femenino la prior (¿prior de qué variable? ¿cuál es el modelo? ¿la probabilidad de no hacer ningún gol es 0?) viene dada por la distribución bimodal en la siguiente figura. Describir el método de Metrópolis para estimar la posterior (¿de qué variable?) y qué cuidados hay que tener en este caso."
  },
  {
    "objectID": "parcial.html#grupo-2",
    "href": "parcial.html#grupo-2",
    "title": "Parcial",
    "section": "Grupo 2",
    "text": "Grupo 2\nSe quiere estimar la probabilidad de que un individuo se baje en un pabellón de Exactas o de FADU en el bondi. En el último censo, del 2018, en Ciudad Universitaria había 27000 estudiantes de FADU y 6000 de exactas. Además, se estima que las estudiantes mujeres son cerca del 65% en FADU y del 30% en Exactas.\n\nHay 3 probabilidades desconocidas: la probabilidad de que alguien (¿un pasajero al azar del colectivo?) sea de Exactas o FADU (¿en 2023?), la probabilidad de que alguien sea hombre siendo de FADU y la probabilidad de que alguien sea hombre siendo de Exactas. Modelá cada una como distribuciones beta con parámetros a elección justificando el por qué de dicha elección. Ayuda: Pensá que los parámetros del prior reflejan tu confianza en los datos provistos en el enunciado.\n¿Cuál es (son? se pide para mujeres y hombres?) la probabilidad a priori de que una persona se baje en un pabellón de Exactas sabiendo su género?\n¿Cómo cambia tu prior (¿cuál prior?¿el de la probabilidad de ser de Exactas) cada vez que observas que alguien baja en una determinada facultad?\nEn el último mes vimos que de las 400 personas que viajaron en colectivo, 140 mujeres y 120 hombres se bajaron en FADU, 75 hombres y 65 mujeres se bajaron en Exactas. ¿Cómo queda la nueva probabilidad de que una persona se baje en un pabellón de exactas sabiendo su género?\nRepetir el mismo proceso pero cuando el prior es uniforme alrededor de los valores presentados. (uniforme entre 0 y 1? qué significa “alrededor de los valores presentados”?)"
  },
  {
    "objectID": "parcial.html#grupo-3",
    "href": "parcial.html#grupo-3",
    "title": "Parcial",
    "section": "Grupo 3",
    "text": "Grupo 3\nFormulas útiles: esperanza de la \\(\\text{Beta}(a, b) = \\frac{a}{a+b}\\).  esperanza de una variable aleatoria con distribución beta: \nInformación: Prior 1 es una Beta(5, 2) (distribución prior de qué variable?) Prior 2 es una Beta(2, 5) (distribución prior de qué variable?)\nDatos de enunciado: 10 intentos de los cuales 8 fueron exitos y 2 fueron fracasos.\nAsumiendo un modelo beta-binomial:\n\nCalcule la posterior de la distribucion (distribución posterior? posterior para qué variable?) teniendo la prior 1 y los datos de enunciado. Debe hacerlo computacional y analiticamente usando fórmulas que conozca.\nComo medida resumen de la distribucion posterior, calcule la esperanza de la calculada en el punto a). Comparar los resultados de la esperanza computacional con la analítica. La esperanza computacional puede calcularla haciendo simulaciones.\nSi en el punto 1) en vez de usar la prior 1 se usara la prior 2, ¿cuál seria la posterior? ¿Cuál de las 2 posterior se ajusta mejor a los datos? Es decir cuál de las 2 posteriors es mas similar a la likelihood. (la posterior es una distribución y el likelihood una función… lo que se puede hacer es generar muestras de 10 observaciones “posterior predictive” y comparar eso con los datos observados)\nSi tuvieras la prior 2, y no se cuenta con los datos de enunciado, cuantos datos de éxito consecutivos se necesitarían para que la esperanza de su posterior sea mayor que la de b)? (asumiendo 0 fracasos). Por ejemplo, si con 5 intentos (y 5 éxitos) la esperanza de la posterior es menor que la de 2, pero con 6 intentos (6 éxitos) la esperanza de la posterior es mayor que la de 2) entonces se necesitan 6 intentos. Sugerencia: Resolver analiticamente utilizando la formula de esperanza de la beta.\nGrafique la posterior de a) y la que cumplio de d). Analice los resultados obtenidos ((se puede ser más específico?) ). Recuerde que para graficar una beta tiene el codigo:\n\n\nA = 50\nB = 10\nxs = seq(0,1,0.001)\nysBetaAB = dbeta(xs, A, B)\nplot(xs,ysBetaAB,type=\"l\")"
  },
  {
    "objectID": "parcial_old.html",
    "href": "parcial_old.html",
    "title": "Parcial",
    "section": "",
    "text": "\\[ \\text{Beta: }f(\\theta \\mid a,b) = \\frac{\\Gamma(a + b)}{\\Gamma(a)\\Gamma(b)} ~ \\theta^{~a-1} ~ (1-\\theta)^{~b-1} ~ \\text{, para } \\theta \\in (0,1) \\]\n\\[ \\text{Gamma: } f(\\lambda \\mid r,s) = \\frac{r^s}{\\Gamma(s)} ~ \\lambda^{~s-1} e^{-r \\lambda} ~ \\text{, para } \\lambda >0 \\]\n\\[ \\text{Binomial: } f(y \\mid N,\\theta) = {N \\choose y}   \\theta^{~y} ~ (1-\\theta)^{~N-y}  ~ \\text{, para } y=0,1,2,...,N \\]\n\\[ \\text{Poisson: } f(y \\mid \\lambda) = \\frac{\\lambda^y~e^{-\\lambda}}{y!} ~ \\text{, para } y=0,1,2,... \\]\n\nConsiderar un modelo beta-binomial con datos y = (y_1, …, y_n), donde y_i = 1 si la variable i es un éxito y 0 en si es un fracaso. Asumir que la distribución a priori para la probabilidad de éxito theta es una beta(a,b).\n\n\nEncontrar la distribución posterior para \\(\\theta\\).\nSuponer un dataset con \\(n=10\\) observaciones, 3 de las cuáles son éxitosy asumir un prior beta(2,2). Graficar la distribución posterior para y calcular la probabilidad de que \\(theta\\) sea menor que 0.4.\n\n\nSuponer una muestra y = (y_1, …, y_n) donde y_i ~ Poisson(theta) para i=1,…,n. Asumir un prior gamma para theta con parámetro shape a y parámetros rate b.\n\n\nUsar la aproximación de grilla para calcular la distribución posterior para theta usando una grilla uniforme de 100 puntos entre 0 y 10.\nAhora suponer que hay una nueva observación y_{n+1} = 3. Usar la distribución posterior del ítem anterior para calcular la nueva distribución posterior para theta usando la aproximación de grilla con la misma grilla que antes.\nDiscutir la secuencialidad en inferencia bayesiana.\nCon esta nueva distribución posterior para theta, encontrar la distribución posterior predictive usando simulaciones. Es decir, la distribución de observaciones que se derivan de esa distribución posterior.\n\n\n\n\nProblem 1: Prior and Posterior Predictive Checks Consider a dataset y = (y_1, …, y_n) where y_i ~ Binomial(5, theta) for i=1,…,n. Assume a beta prior distribution for theta with parameters a = 2 and b = 2.\n\nUsing a grid approximation approach with a uniform grid of 100 points between 0 and 1, calculate the posterior distribution for theta.\nGenerate 1000 samples from the posterior distribution of theta, and use these samples to simulate 1000 new datasets of size n = 10.\nPerform a prior predictive check and posterior predictive check for the original dataset y, and discuss your findings.\n\nProblem 3: Sequential Bayesian Updating Consider a dataset y = (y_1, …, y_n) where y_i ~ Binomial(10, theta) for i=1,…,n. Assume a beta prior distribution for theta with parameters a = 2 and b = 2.\n\nUsing a grid approximation approach with a uniform grid of 100 points between 0 and 1, calculate the posterior distribution for theta for the first 5 observations y_1, …, y_5.\nNow suppose you observe a new data point y_6 = 8. Using the posterior distribution from part (a) as the prior, calculate the new posterior distribution for theta using a grid approximation approach with the same grid as before.\nRepeat part (b) for each subsequent observation y_7, …, y_n. Discuss how the posterior distribution changes as more data is observed, and how this relates to the concept of sequential Bayesian updating.\n\nProblem 1: Grid Approximation and Sampling the Posterior Consider a dataset y = (y_1, …, y_n) where y_i ~ Bernoulli(theta) for i=1,…,n. Assume a beta prior distribution for theta with parameters a = 1 and b = 1.\n\nUsing a grid approximation approach with a uniform grid of 100 points between 0 and 1, calculate the posterior distribution for theta.\n\n\nSet up the data and prior parameters\ny <- c(1, 0, 1, 1, 0, 1, 0, 0, 1, 1) n <- length(y) a <- 1 b <- 1\n\n\nSet up the grid\ntheta_grid <- seq(0, 1, length.out = 100)\n\n\nCalculate the likelihood for each value of theta\nlikelihood <- ______________________________\n\n\nCalculate the unnormalized posterior\nunnormalized_posterior <- ___________________________\n\n\nNormalize the posterior\nposterior <- _________________________\n\n\nPlot the posterior distribution\nplot(theta_grid, posterior, type = “l”, xlab = “theta”, ylab = “Density”)\n\nUsing a Metropolis-Hastings algorithm with a normal proposal distribution, sample from the posterior distribution for theta using the dataset y = (1, 0, 1, 1, 0, 1, 0, 0, 1, 1).\n\n\n\nDefine the log-likelihood function\nlog_likelihood <- function(theta, y) { sum(dbinom(y, 1, theta, log = TRUE)) }\n\n\nDefine the log-prior function\nlog_prior <- function(theta, a, b) { dbeta(theta, a, b, log = TRUE) }\n\n\nDefine the log-posterior function\nlog_posterior <- function(theta, y, a, b) { log_likelihood(theta, y) + log_prior(theta, a, b) }\n\n\nSet the initial value for theta and the number of iterations\ntheta_init <- 0.5 n_iter <- 10000\n\n\nDefine the standard deviation of the proposal distribution\nsd_proposal <- 0.1\n\n\nCreate a vector to store the samples\ntheta_samples <- numeric(n_iter)\n\n\nSet the first value to the initial value\ntheta_samples[1] <- theta_init\n\n\nDefine the acceptance rate\nacceptance_rate <- 0\n\n\nRun the Metropolis-Hastings algorithm\nfor (i in 2:n_iter) { # Sample from the proposal distribution theta_proposal <- rnorm(1, theta_samples[i-1], sd_proposal)\n# Calculate the acceptance probability log_accept_prob <- min(0, log_posterior(theta_proposal, y, a, b) - log_posterior(theta_samples[i-1], y, a, b)) accept_prob <- exp(log_accept_prob)\n# Accept or reject the proposal if (runif(1) < accept_prob) { theta_samples[i] <- theta_proposal acceptance_rate <- acceptance_rate + 1/n_iter } else { theta_samples[i] <- theta_samples[i-1] } }\n\n\nPlot the posterior distribution\nhist(theta_samples, breaks = 30, freq = FALSE, xlab = “theta”, main = “Posterior Distribution”)\nProblem 3: Posterior Predictive Checks Consider a dataset y = (y_1, …, y_n) where y_i ~ Poisson(lambda) for i=1,…,n. Assume a gamma(2, 1) prior distribution for lambda.\n\nCalculate the posterior predictive distribution for a new data point y_{n+1} using the dataset y = (1, 3, 0, 2, 1, 5, 2, 3, 1, 2).\n\n\n\nSet up the data and prior parameters\ny <- c(1, 3, 0, 2, 1, 5, 2, 3, 1, 2) n <- length(y) a <- 2 b <- 1\n\n\nSet up the grid\nlambda_grid <- seq(0, 20, length.out = 1000)\n\n\nCalculate the unnormalized posterior\nunnormalized_posterior <- dgamma(lambda_grid, a + sum(y), b + n)\n\n\nNormalize the posterior\nposterior <- unnormalized_posterior / sum(unnormalized_posterior)\n\n\nCalculate the posterior predictive distribution for a new data point\nposterior_predictive <- dpois(y = 1, lambda = lambda_grid) * posterior\n\n\nCalculate the posterior predictive distribution for a new data point\nposterior_predictive <- dpois(y = 1, lambda = lambda_grid) * posterior\n\n\nCalculate the predictive mean and variance\npredictive_mean <- sum(posterior_predictive * lambda_grid) predictive_var <- sum(posterior_predictive * (lambda_grid - predictive_mean)^2)\n\n\nPrint the results\ncat(“Predictive mean:”, predictive_mean, “”) cat(“Predictive variance:”, predictive_var, “”)\n\nPerform a posterior predictive check by generating 1000 new datasets from the posterior predictive distribution and calculating the proportion of datasets for which the sum of the new data points is greater than or equal to the sum of the original data points.\n\n\n\nGenerate 1000 new datasets from the posterior predictive distribution\nn_sims <- 1000 new_data <- rpois(n = n_sims, lambda = rnorm(n_sims, predictive_mean, sqrt(predictive_var)))\n\n\nCalculate the sum of the new data points for each simulated dataset\nnew_data_sum <- apply(new_data, 2, sum)\n\n\nCalculate the proportion of datasets for which the sum of the new data points is greater than or equal to the sum of the original data points\nprop_greater_or_equal <- mean(new_data_sum >= sum(y))\n\n\nPrint the results\ncat(“Proportion of datasets for which the sum of the new data points is greater than or equal to the sum of the original data points:”, prop_greater_or_equal, “”)"
  },
  {
    "objectID": "ejercicios.html#guía-4-modelo-lineal---introducción-a-brms",
    "href": "ejercicios.html#guía-4-modelo-lineal---introducción-a-brms",
    "title": "Guías de problemas",
    "section": "Guía 4: Modelo lineal - Introducción a brms",
    "text": "Guía 4: Modelo lineal - Introducción a brms\n\nPara el siguiente modelo, simular observaciones \\(y_{obs}\\) con el prior\n\n\\[\ny \\sim \\text{Normal}(\\mu, \\sigma) \\\\\n\\mu = \\text{Normal}(0,10) \\\\\n\\sigma = \\text{Exponencial}(1)\n\\]\n\nEscribir el modelo del ejercicio 1 en brms.\nTraducir el siguiente modelo (en sintaxis de brms) matemáticamente>\n\n\n      family = gaussian, \n      y ~ 1 + x,\n      prior = c(prior(normal(0, 10), class = Intercept),\n                prior(normal(0, 10), class = b),\n                prior(exp(1),  class = sigma))\n\n\nSupongamos que se mide la altura de un grupo de chicos durante tres años. Al cabo de los tres años, se quiere usar un modelo lineal para predecir la altura usando el año como predictora. Escribir la definición matemática para este modelo de regresión, usando los priors que quiera (pero esté preparado para defender la elección de priors.)\nUsando el dataset de alturas Howell1 que viene con el paquete rethinking, dar una predicción para la altura de individuos que pesan 46.95, 43.72, 64.78, 32.59 y 54.63 Kg. Dar también un intervalo de credibilidad del 95% para estas predicciones.\nDel mismo dataset, seleccionar sólo los individuos que tienen menos de 18 años. Ajustar con brms un modelo de regresión lineal para la altura teniendo como explicativa al peso de los individuos. Graficar los datos y la recta obtenida con los valores medios de la posterior y un intervalo de credibilidad para esos valores. También graficar un intervalo de credibilidad para la altura predicha por el modelo. Todo en el mismo gráfico. ¿Te parece adecuado el modelo? ¿Qué aspectos podrías cambiar para mejorar el modelo?"
  },
  {
    "objectID": "ejercicios.html#guía-5-regresiones",
    "href": "ejercicios.html#guía-5-regresiones",
    "title": "Guías de problemas",
    "section": "Guía 5: Regresiones",
    "text": "Guía 5: Regresiones\n\nUsando el dataset penguins del paquete palmerpenguins, estudiar la relación entre el largo de las aletas de los pinguinos (flipper_length) y su peso (body_mass_g).\n\nProponer un modelo en el que el peso tiene una distribución normal con parámetros \\(\\mu\\) y \\(\\sigma\\), donde \\(\\mu\\) se basa en el largo de las aletas.\nCorrer el modelo en STAN usando brms o rstanarm, eligiendo priors para los parámetros o usando los priors default.\nDiagnosticar las cadenas de muestras de las posteriores para cada parámetro usando el número efectivo de muestras (\\(n_{eff}\\)) y \\(\\hat{R}\\).\nEncontrar la distribución posterior para el peso esperado de un pinguino que tiene una aleta de largo 200 mm. Graficarla y dar medidas resumen.\nHacer 500 predicciones del peso de un pinguino con una aleta de largo 200 mm. Graficar la distribución de estos pesos predichos y comparar con el resultado del ítem anterior. ¿A qué se debe la diferencia?\nGraficar 100 rectas correspondientes al peso esperado de pinguinos con una aleta de largo entre 150 mm y 250 mm. Hacer lo mismo para el peso predicho por el modelo.\n\nProponer un modelo de regresión logística para clasificar a un pinguino como de la especie Gentoo usando como variable predictora al largo del pico (bill_length).\n\nCorrer el modelo y extraer la probabilidad de que un pinguino sea Gentoo si su pico tiene largo 40 mm. (Ayuda: se puede usar la función posterior_linpred(transform = TRUE)).\nGraficar la probabilidad de que un pinguino sea Gentoo en función del largo del pico.\n\nSe quiere entender la relación entre el cociente de ancho y largo del pico (\\(r\\), variable respuesta) y el largo de la aleta (variable explicativa). Proponga un modelo (tenga en cuenta el rango posible de valores de \\(r\\) para elegir la distribución de la variable respuesta). Ajustar el modelo y graficar los valores de \\(r\\) predichos por el modelo para un rango de valores para el largo de la aleta entre 170 mm y 240 mm."
  }
]